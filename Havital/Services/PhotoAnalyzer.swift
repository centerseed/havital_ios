import UIKit
import SwiftUI
import CoreImage
import Vision

/// ç…§ç‰‡åˆ†æå™¨ - ç”¨æ–¼åˆ†æç…§ç‰‡äº®åº¦ã€æ§‹åœ–ä¸¦æ¨è–¦æœ€ä½³åˆ†äº«å¡ç‰ˆå‹
class PhotoAnalyzer {

    // MARK: - Public Methods

    /// åˆ†æç…§ç‰‡ä¸¦æ¨è–¦ç‰ˆå‹
    func analyze(_ image: UIImage) -> PhotoAnalysisResult {
        let brightness = calculateBrightness(image)
        let subjectPosition = detectSubjectPosition(image)
        let dominantColors = extractDominantColors(image)

        // ç‰ˆå‹æ¨è–¦é‚è¼¯
        let layout = suggestLayout(brightness: brightness, subjectPosition: subjectPosition)

        // æ–‡å­—é¡è‰²æ¨è–¦
        let textColor: Color = brightness > 0.5 ? .black : .white

        // é…è‰²æ–¹æ¡ˆæ¨è–¦
        let colorScheme: ShareCardColorScheme
        switch layout {
        case .top:
            colorScheme = .topGradient
        case .bottom, .side:
            colorScheme = brightness > 0.5 ? .light : .default
        case .auto:
            colorScheme = .default
        }

        return PhotoAnalysisResult(
            brightness: brightness,
            subjectPosition: subjectPosition,
            dominantColors: dominantColors,
            suggestedLayout: layout,
            suggestedTextColor: textColor,
            suggestedColorScheme: colorScheme
        )
    }

    // MARK: - Private Methods

    /// è¨ˆç®—ç…§ç‰‡å¹³å‡äº®åº¦ (0-1)
    private func calculateBrightness(_ image: UIImage) -> Double {
        guard let ciImage = CIImage(image: image) else {
            print("âš ï¸ [PhotoAnalyzer] ç„¡æ³•è½‰æ›ç‚º CIImage,ä½¿ç”¨é è¨­äº®åº¦")
            return 0.5
        }

        let extent = ciImage.extent

        // ä½¿ç”¨ CIAreaAverage æ¿¾é¡è¨ˆç®—å¹³å‡é¡è‰²
        guard let filter = CIFilter(name: "CIAreaAverage", parameters: [
            kCIInputImageKey: ciImage,
            kCIInputExtentKey: CIVector(cgRect: extent)
        ]) else {
            print("âš ï¸ [PhotoAnalyzer] ç„¡æ³•å‰µå»º CIAreaAverage æ¿¾é¡")
            return 0.5
        }

        guard let outputImage = filter.outputImage else {
            print("âš ï¸ [PhotoAnalyzer] æ¿¾é¡è¼¸å‡ºç‚ºç©º")
            return 0.5
        }

        // å°‡è¼¸å‡ºåœ–åƒè½‰æ›ç‚º bitmap
        var bitmap = [UInt8](repeating: 0, count: 4)
        let context = CIContext(options: [.workingColorSpace: kCFNull as Any])
        context.render(
            outputImage,
            toBitmap: &bitmap,
            rowBytes: 4,
            bounds: CGRect(x: 0, y: 0, width: 1, height: 1),
            format: .RGBA8,
            colorSpace: nil
        )

        // è¨ˆç®—äº®åº¦ (ä½¿ç”¨ç›¸å°äº®åº¦å…¬å¼)
        let red = Double(bitmap[0]) / 255.0
        let green = Double(bitmap[1]) / 255.0
        let blue = Double(bitmap[2]) / 255.0

        // ç›¸å°äº®åº¦å…¬å¼: Y = 0.299R + 0.587G + 0.114B
        let brightness = 0.299 * red + 0.587 * green + 0.114 * blue

        print("ğŸ“Š [PhotoAnalyzer] ç…§ç‰‡äº®åº¦: \(String(format: "%.2f", brightness))")

        return brightness
    }

    /// åµæ¸¬ç…§ç‰‡ä¸­çš„ä¸»é«”ä½ç½®
    private func detectSubjectPosition(_ image: UIImage) -> SubjectPosition {
        guard let cgImage = image.cgImage else {
            print("âš ï¸ [PhotoAnalyzer] ç„¡æ³•è½‰æ›ç‚º CGImage,ä½¿ç”¨é è¨­ä½ç½®")
            return .center
        }

        // ä½¿ç”¨ Vision æ¡†æ¶åµæ¸¬äººè‡‰
        let request = VNDetectFaceRectanglesRequest()
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])

        do {
            try handler.perform([request])

            if let observations = request.results, !observations.isEmpty {
                // æ‰¾åˆ°äººè‡‰,æ ¹æ“šäººè‡‰ä½ç½®åˆ¤æ–·ä¸»é«”ä½ç½®
                let firstFace = observations[0]
                let boundingBox = firstFace.boundingBox

                // Vision æ¡†æ¶çš„åº§æ¨™ç³»çµ±: åŸé»åœ¨å·¦ä¸‹è§’
                let centerY = boundingBox.midY
                let centerX = boundingBox.midX

                print("ğŸ“Š [PhotoAnalyzer] åµæ¸¬åˆ°äººè‡‰ä½ç½®: (\(String(format: "%.2f", centerX)), \(String(format: "%.2f", centerY)))")

                // åˆ¤æ–·ä¸»é«”ä½ç½®
                if centerY > 0.6 {
                    return .top  // äººè‡‰åœ¨ä¸Šæ–¹
                } else if centerY < 0.4 {
                    return .bottom  // äººè‡‰åœ¨ä¸‹æ–¹
                } else if centerX < 0.4 {
                    return .left  // äººè‡‰åœ¨å·¦å´
                } else if centerX > 0.6 {
                    return .right  // äººè‡‰åœ¨å³å´
                } else {
                    return .center  // äººè‡‰åœ¨ä¸­å¤®
                }
            }
        } catch {
            print("âš ï¸ [PhotoAnalyzer] äººè‡‰åµæ¸¬å¤±æ•—: \(error.localizedDescription)")
        }

        // å¦‚æœæ²’æœ‰åµæ¸¬åˆ°äººè‡‰,ä½¿ç”¨é¡¯è‘—æ€§åˆ†æ
        return detectSaliency(cgImage)
    }

    /// ä½¿ç”¨é¡¯è‘—æ€§åˆ†æåµæ¸¬ä¸»é«”ä½ç½®
    private func detectSaliency(_ cgImage: CGImage) -> SubjectPosition {
        let request = VNGenerateAttentionBasedSaliencyImageRequest()
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])

        do {
            try handler.perform([request])

            if let observation = request.results?.first as? VNSaliencyImageObservation {
                // åˆ†æé¡¯è‘—å€åŸŸçš„ä¸­å¿ƒé»
                let salientObjects = observation.salientObjects ?? []

                if !salientObjects.isEmpty {
                    let centerY = salientObjects.map { $0.boundingBox.midY }.reduce(0, +) / Double(salientObjects.count)
                    let centerX = salientObjects.map { $0.boundingBox.midX }.reduce(0, +) / Double(salientObjects.count)

                    print("ğŸ“Š [PhotoAnalyzer] é¡¯è‘—æ€§ä¸­å¿ƒ: (\(String(format: "%.2f", centerX)), \(String(format: "%.2f", centerY)))")

                    if centerY > 0.6 {
                        return .top
                    } else if centerY < 0.4 {
                        return .bottom
                    } else if centerX < 0.4 {
                        return .left
                    } else if centerX > 0.6 {
                        return .right
                    } else {
                        return .center
                    }
                }
            }
        } catch {
            print("âš ï¸ [PhotoAnalyzer] é¡¯è‘—æ€§åˆ†æå¤±æ•—: \(error.localizedDescription)")
        }

        // é è¨­è¿”å›ä¸­å¤®
        print("ğŸ“Š [PhotoAnalyzer] ä½¿ç”¨é è¨­ä½ç½®: center")
        return .center
    }

    /// æå–ä¸»è¦é¡è‰²
    private func extractDominantColors(_ image: UIImage) -> [Color] {
        // TODO: å¯¦ç¾ K-Means é¡è‰²èšé¡
        // ç›®å‰è¿”å›ç©ºæ•¸çµ„,å¾ŒçºŒå¯å¯¦ç¾æ›´è¤‡é›œçš„é¡è‰²åˆ†æ
        return []
    }

    /// æ ¹æ“šäº®åº¦å’Œä¸»é«”ä½ç½®æ¨è–¦ç‰ˆå‹
    private func suggestLayout(brightness: Double, subjectPosition: SubjectPosition) -> ShareCardLayoutMode {
        print("ğŸ“Š [PhotoAnalyzer] äº®åº¦: \(String(format: "%.2f", brightness)), ä¸»é«”ä½ç½®: \(subjectPosition)")

        switch (brightness, subjectPosition) {
        case (0.7...1.0, .bottom):
            // äº®èƒŒæ™¯ + äººç‰©åä¸‹ â†’ åº•éƒ¨æ©«æ¢
            print("ğŸ“Š [PhotoAnalyzer] æ¨è–¦ç‰ˆå‹: bottom (äº®èƒŒæ™¯ + ä¸»é«”åä¸‹)")
            return .bottom

        case (0.3...0.7, .left), (0.3...0.7, .right):
            // ä¸­ç­‰äº®åº¦ + äººç‰©åå´ â†’ å´é‚Šæµ®å±¤
            print("ğŸ“Š [PhotoAnalyzer] æ¨è–¦ç‰ˆå‹: side (ä¸­ç­‰äº®åº¦ + ä¸»é«”åå´)")
            return .side

        case (0.0...0.3, _):
            // æš—èƒŒæ™¯ â†’ é ‚éƒ¨ç½®ä¸­
            print("ğŸ“Š [PhotoAnalyzer] æ¨è–¦ç‰ˆå‹: top (æš—èƒŒæ™¯)")
            return .top

        default:
            // é è¨­ä½¿ç”¨åº•éƒ¨æ©«æ¢
            print("ğŸ“Š [PhotoAnalyzer] æ¨è–¦ç‰ˆå‹: bottom (é è¨­)")
            return .bottom
        }
    }
}
